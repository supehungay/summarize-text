{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\NLPandDeeplearning\\final\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import  load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum = billsum.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The people of the State of California do enact as follows:\\n\\n\\nSECTION 1.\\n(a) The Legislature finds and declares the following:\\n(1)\\nA new form of work has proliferated in which individuals work by the job through an electronic platform, such as the Internet or telephone. These individuals are hired through these hosting platforms to perform short-term work, usually of a day or less, for multiple customers.\\n(2)\\nThese individuals are not treated by the hosting platforms as employees and do not receive the benefit of state labor protection laws such as minimum wage, unemployment insurance, and workers’ compensation. The platforms treat these individuals as independent contractors and even though they perform work for multiple clients, usually individual people, the individuals securing work through a hosting platform are normally prohibited from negotiating the terms of their services. Instead, the hosting platforms dictate the terms and take a considerable portion of the amount paid for services, even though the hosting platforms purport that they provide only a means of connecting workers with clients.\\n(3)\\nThese are circumstances that inevitably lead to exploitation. The people who secure work through the hosting platforms may in fact be employees, but establishing their true status often requires lengthy and expensive litigation during the pendency of which they continue to have no protection.\\n(b)\\nThe Legislature therefore finds and declares that the bargaining power between the hosting platforms and the people seeking work through them must be better balanced and creates in this act a process for these workers to get together and negotiate with the hosting platforms for the improvements they desire.\\n(c) The Legislature further finds and declares that, through these negotiations, these workers will be able to improve their conditions, including their income, to the benefit of the economy of this state and reduce pressure on public resources.\\nSECTION 1.\\nSEC. 2.\\nChapter 4.8 (commencing with Section 1080) is added to Part 3 of Division 2 of the Labor Code, to read:\\nCHAPTER  4.8. Hosting Platforms\\n1080.\\nAs used in this chapter:\\n(a) “Group activity” means to self-organize, to negotiate as a group with one or more hosting platforms, or to engage together in other activities for the purpose of group negotiations or other mutual aid or protection, which activity includes, but is not limited, to the following:\\n(1) Communicating with each other and with hosting platforms, customers, and the public through any medium, including, but not limited to, social media and other electronic modes of communication.\\n(2) Withholding or restricting the amount of work done through a hosting platform at any time and for any duration. This paragraph does not apply to an independent contractor who performs “supportive services,” as defined in Section 12300.1 of the Welfare and Institutions Code.\\n(3) Boycotting or critiquing a hosting platform’s business practices.\\n(4) Reporting to law enforcement authorities or making public practices of a hosting platform which an independent contractor reasonably believes violate local, state, or federal law and adversely affect either workers or clients, or both.\\n(b) “Hosting platform” is a facility for connecting people or entities seeking to hire people for work with people seeking to perform that work, using any medium of facilitation, including, but not limited to, a dispatch service, an Internet Web site, or other Internet-based site. “Hosting platform” does not include a service provider if that entity provides only listings of goods or services that are contracted directly between buyers and sellers without the involvement of the provider and receives no income related to the price of the transaction.\\n1081.\\n(a) An independent contractor who is not treated by a hosting platform as an employee and who does not employ his or her own employees shall have the right to engage in group activity with respect to one or more hosting platforms.\\n(b) Work by an independent contractor, including the use of equipment or goods supplied as part of the work performed by the independent contractor, is labor within the meaning of Section 16703 of the Business and Professions Code and group activity by independent contractors shall not be subject to any statutory or common law prohibition or limitation on combinations in restraint of trade, including, but not limited to, Chapter 2 (commencing with Section 16700) of Part 2 of Division 7 of the Business and Professions Code.\\n(c) Group activity is a “labor dispute” within the meaning of Section 527.3 of the Code of Civil Procedure and Section 1138.1, provided that a court may issue injunctive relief to remedy violations of this chapter pursuant to\\nSections ____ and ____.\\nsubdivisions (e) and (g).\\n(d) (1) A hosting platform shall meet at reasonable times and negotiate in good faith about allowed subjects for negotiation with any group of independent contractors constituting at least 10 of the independent contractors using the platform on an average of at least once per week. As used in this paragraph, “allowed subjects for negotiation” are pricing, division of revenue, priority for assignments or listings, advertising by independent contractors on the hosting platform, insurance, acceptance and termination of independent contractor participation on the hosting platform, acceptance or refusal of services by independent contractors or customers, and responsibility for nonpayment by customers.\\n(2) An individual or organization that represents independent contractors in negotiations with a hosting platform regarding the allowed subjects of negotiation pursuant to this section shall not be funded directly or indirectly by a hosting platform.\\n(3) Participation in the group shall be evidenced by an electronic communication from an independent contractor using the same address the independent contractor uses to communicate with the hosting platform, or a physical document signed by the independent contractor, sent to either the hosting platform or to one or more other members of the group accepting participation in the group and agreeing to be bound contractually by the outcome of any negotiations between the group and the hosting platform. An independent contractor shall not be bound by the outcome of any negotiations between a group and a hosting platform unless the independent contractor has given that authorization.\\n(4) At the request of the group, a written contract for independent contractor services, entered into on or after the date of the conclusion of negotiations conducted in accordance with paragraph (1), between the hosting platform and a member of that group, shall incorporate any agreement reached in those negotiations.\\n(e) The State Mediation and Conciliation Service shall facilitate the performance of the obligation of a hosting platform under subdivision (d). The State Mediation and Conciliation Service shall provide meeting space for negotiations unless the hosting platform and the group make other arrangements that are mutually agreeable. The State Mediation and Conciliation Service shall provide mediation services at the request of either the hosting platform or the group. The State Mediation and Conciliation Service shall investigate any complaint by a group claiming a violation of subdivision (d), and, if it finds that there is probable cause to believe a violation has occurred, bring an action in the Superior Court of the State of California for the City and County of San Francisco for injunctive and other appropriate equitable relief to remedy the violation. The court shall award reasonable attorney’s fees and costs to the State Mediation and Conciliation Service if it prevails in any enforcement action.\\n(f) A person shall not terminate, discriminate against, or otherwise penalize or retaliate against any independent contractor for exercising any rights established in this chapter or for making a complaint, participating in any enforcement proceedings under this chapter, using any civil remedies to enforce his or her rights, or otherwise asserting his or her rights under this chapter or demonstrating his or her support for the policies of this chapter. A person terminating or taking any other adverse action against any independent contractor who has engaged in any of the foregoing activities within one year preceding the termination or other adverse action shall provide to the independent contractor at or before the time of the termination or other adverse action a detailed written statement of the reason or reasons for the termination or other adverse action, including all the facts substantiating the reason or reasons and all facts known to the person that contradict the substantiating facts.\\n(g) An independent contractor or a representative of one or more independent contractors claiming a violation of this chapter may bring an action in superior court and shall be entitled to all remedies available under the law or in equity appropriate to remedy that violation, including, but not limited to, injunctive relief or other equitable relief, including reinstatement to participation in a hosting platform and compensatory damages. For a willful violation of subdivision (d), the amount of damages attributable to lost income due to the violation shall be trebled.\\n1082.\\n(a) The exercise of any rights established by this chapter shall not be admissible as evidence that a person is an independent contractor in any judicial or administrative proceeding.\\n(b) Nothing in this chapter is intended to impact the determination of whether any worker is an employee or independent contractor or to impact any pending litigation.\\n1082.\\n1083.\\nThe provisions of this chapter are severable. If any provision of this chapter or its application is held invalid, that invalidity shall not affect other provisions or applications that can be given effect without the invalid provision or application.',\n",
       " 'summary': 'Existing law relating to employment governs the grant of restraining orders or injunctive relief in labor disputes, as defined.\\nThis bill would establish for eligible groups of independent contractors the right to organize and negotiate with hosting platforms, and would declare the activity of such a group to be a labor dispute for purposes of injunctive relief. The bill would require a hosting platform to meet and negotiate with a group on specified subjects. The bill would define terms for those purposes.\\nThe bill would require that, at the request of the group, a written contract for independent contractor services, entered into on or after the date of the conclusion of negotiations conducted in accordance with the bill, by the hosting platform and a member of that group, incorporate any agreement reached in those negotiations.\\nThe bill would require the State Mediation and Conciliation Service to facilitate negotiations, provide mediation services, and investigate any complaint by a group claiming a violation of the negotiation requirement. The bill would require the service, if it finds that there is probable cause to believe a violation has occurred, to bring an action in a specified superior court for injunctive and other appropriate equitable relief to remedy the violation.\\nThe bill would prohibit a person from penalizing or retaliating against an independent contractor for taking specified actions within the scope of the bill.\\nThe bill would authorize an independent contractor or a representative of independent contractors claiming a violation under this bill to bring an action in superior court for prescribed remedies, and would provide for treble damages with regard to lost income for a willful violation.\\nThe exercise of any rights established by the bill would not be admissible as evidence that a person is an independent contractor in any judicial or administrative proceeding.\\nThe bill would make its provisions severable.',\n",
       " 'title': 'An act to add Chapter 4.8 (commencing with Section 1080) to Part 3 of Division 2 of the Labor Code, relating to employment.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "checkpoint = \"t5-small\"\n",
    "access_token = \"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\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'summary', 'title'],\n",
       "        num_rows: 989\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'summary', 'title'],\n",
       "        num_rows: 248\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_awesome_billsum_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\NLPandDeeplearning\\final\\notebooks\\test.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m training_args \u001b[39m=\u001b[39m Seq2SeqTrainingArguments(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmy_awesome_billsum_model\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     push_to_hub\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m trainer \u001b[39m=\u001b[39m Seq2SeqTrainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     args\u001b[39m=\u001b[39;49mtraining_args,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mtokenized_billsum[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     eval_dataset\u001b[39m=\u001b[39;49mtokenized_billsum[\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     data_collator\u001b[39m=\u001b[39;49mdata_collator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39;49mcompute_metrics,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[1;32md:\\NLPandDeeplearning\\final\\.venv\\lib\\site-packages\\transformers\\trainer_seq2seq.py:56\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     43\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     44\u001b[0m     model: Union[\u001b[39m\"\u001b[39m\u001b[39mPreTrainedModel\u001b[39m\u001b[39m\"\u001b[39m, nn\u001b[39m.\u001b[39mModule] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     preprocess_logits_for_metrics: Optional[Callable[[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor], torch\u001b[39m.\u001b[39mTensor]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     55\u001b[0m ):\n\u001b[1;32m---> 56\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     57\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     58\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m     59\u001b[0m         data_collator\u001b[39m=\u001b[39;49mdata_collator,\n\u001b[0;32m     60\u001b[0m         train_dataset\u001b[39m=\u001b[39;49mtrain_dataset,\n\u001b[0;32m     61\u001b[0m         eval_dataset\u001b[39m=\u001b[39;49meval_dataset,\n\u001b[0;32m     62\u001b[0m         tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[0;32m     63\u001b[0m         model_init\u001b[39m=\u001b[39;49mmodel_init,\n\u001b[0;32m     64\u001b[0m         compute_metrics\u001b[39m=\u001b[39;49mcompute_metrics,\n\u001b[0;32m     65\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m     66\u001b[0m         optimizers\u001b[39m=\u001b[39;49moptimizers,\n\u001b[0;32m     67\u001b[0m         preprocess_logits_for_metrics\u001b[39m=\u001b[39;49mpreprocess_logits_for_metrics,\n\u001b[0;32m     68\u001b[0m     )\n\u001b[0;32m     70\u001b[0m     \u001b[39m# Override self.model.generation_config if a GenerationConfig is specified in args.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Priority: args.generation_config > model.generation_config > default GenerationConfig.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgeneration_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\NLPandDeeplearning\\final\\.venv\\lib\\site-packages\\transformers\\trainer.py:536\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhub_model_id \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub:\n\u001b[1;32m--> 536\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_hf_repo()\n\u001b[0;32m    537\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n\u001b[0;32m    538\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39moutput_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\NLPandDeeplearning\\final\\.venv\\lib\\site-packages\\transformers\\trainer.py:3478\u001b[0m, in \u001b[0;36mTrainer.init_hf_repo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3475\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3476\u001b[0m     repo_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_model_id\n\u001b[1;32m-> 3478\u001b[0m repo_url \u001b[39m=\u001b[39m create_repo(repo_name, token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_token, private\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_private_repo, exist_ok\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   3479\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhub_model_id \u001b[39m=\u001b[39m repo_url\u001b[39m.\u001b[39mrepo_id\n\u001b[0;32m   3480\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_in_progress \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\NLPandDeeplearning\\final\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\NLPandDeeplearning\\final\\.venv\\lib\\site-packages\\huggingface_hub\\hf_api.py:2800\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[1;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[0;32m   2796\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_lfsmultipartthresh\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2797\u001b[0m     \u001b[39m# Testing purposes only.\u001b[39;00m\n\u001b[0;32m   2798\u001b[0m     \u001b[39m# See https://github.com/huggingface/huggingface_hub/pull/733/files#r820604472\u001b[39;00m\n\u001b[0;32m   2799\u001b[0m     json[\u001b[39m\"\u001b[39m\u001b[39mlfsmultipartthresh\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lfsmultipartthresh  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m-> 2800\u001b[0m headers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_hf_headers(token\u001b[39m=\u001b[39;49mtoken, is_write_action\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   2802\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m   2803\u001b[0m     r \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39mpost(path, headers\u001b[39m=\u001b[39mheaders, json\u001b[39m=\u001b[39mjson)\n",
      "File \u001b[1;32md:\\NLPandDeeplearning\\final\\.venv\\lib\\site-packages\\huggingface_hub\\hf_api.py:6943\u001b[0m, in \u001b[0;36mHfApi._build_hf_headers\u001b[1;34m(self, token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m   6940\u001b[0m \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   6941\u001b[0m     \u001b[39m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[0;32m   6942\u001b[0m     token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken\n\u001b[1;32m-> 6943\u001b[0m \u001b[39mreturn\u001b[39;00m build_hf_headers(\n\u001b[0;32m   6944\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   6945\u001b[0m     is_write_action\u001b[39m=\u001b[39;49mis_write_action,\n\u001b[0;32m   6946\u001b[0m     library_name\u001b[39m=\u001b[39;49mlibrary_name \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlibrary_name,\n\u001b[0;32m   6947\u001b[0m     library_version\u001b[39m=\u001b[39;49mlibrary_version \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlibrary_version,\n\u001b[0;32m   6948\u001b[0m     user_agent\u001b[39m=\u001b[39;49muser_agent \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muser_agent,\n\u001b[0;32m   6949\u001b[0m )\n",
      "File \u001b[1;32md:\\NLPandDeeplearning\\final\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\NLPandDeeplearning\\final\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_headers.py:122\u001b[0m, in \u001b[0;36mbuild_hf_headers\u001b[1;34m(token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39m# Get auth token to send\u001b[39;00m\n\u001b[0;32m    121\u001b[0m token_to_send \u001b[39m=\u001b[39m get_token_to_send(token)\n\u001b[1;32m--> 122\u001b[0m _validate_token_to_send(token_to_send, is_write_action\u001b[39m=\u001b[39;49mis_write_action)\n\u001b[0;32m    124\u001b[0m \u001b[39m# Combine headers\u001b[39;00m\n\u001b[0;32m    125\u001b[0m headers \u001b[39m=\u001b[39m {\n\u001b[0;32m    126\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m: _http_user_agent(\n\u001b[0;32m    127\u001b[0m         library_name\u001b[39m=\u001b[39mlibrary_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m     )\n\u001b[0;32m    131\u001b[0m }\n",
      "File \u001b[1;32md:\\NLPandDeeplearning\\final\\.venv\\lib\\site-packages\\huggingface_hub\\utils\\_headers.py:172\u001b[0m, in \u001b[0;36m_validate_token_to_send\u001b[1;34m(token, is_write_action)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m is_write_action:\n\u001b[0;32m    171\u001b[0m     \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    173\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mToken is required (write-access action) but no token found. You need\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m to provide a token or be logged in to Hugging Face with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m `huggingface-cli login` or `huggingface_hub.login`. See\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m https://huggingface.co/settings/tokens.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m         )\n\u001b[0;32m    178\u001b[0m     \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mapi_org\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    179\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    180\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou must use your personal account token for write-access methods. To\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m generate a write-access token, go to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m https://huggingface.co/settings/tokens\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens."
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_awesome_billsum_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"], \n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\NLPandDeeplearning\\final\\notebooks\\test.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NLPandDeeplearning/final/notebooks/test.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39mpush_to_hub()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
